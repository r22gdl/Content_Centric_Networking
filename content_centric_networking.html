<!DOCTYPE html>
<html>
<head>
        <link rel=StyleSheet href="stylesheet.css" type="text/css">
        <title>Final Project Raphael Osorio</title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
</head>
<body>

<h1 class="center1">Content Centric Networks as related to Net Neutrality</h1>

<h2>Content-Centric Networks as Related to  Net Neutrality</h2>
<p>The current issue over net neutrality resides in the way the web is structured. We say that the web and HTTP are a destnation oriented system because they rely on uniquely identifying users and destinations. Accordingly, internet service providers have the ability to single out heavy bandwidth users such as video streaming applications. ISPs can bias their service in favor of or against specific entities. In January of 2014, the U.S. appeals court suspended federal rules forcing broadband providers to treat all Internet traffic, effectively granting them this new power. In their defense, Charter Communications Chief Executive Tom Rutledge explains that all broadband capacity is &rsquo;paid for by the consumer,&rsquo; but &rsquo;you could argue that it would be more efficient for consumers if the people who are taking the bandwidth for a product were paying for the bandwidth in some fair and proportional way.&rsquo;(link1) In a similar spirit, Verizon and other Internet-service providers said the ruling would have little impact on the way consumers experience the Internet. &rsquo;Verizon has been and remains committed to the open Internet which provides consumers with competitive choices and unblocked access to lawful websites and content when, where, and how they want,&rsquo; said (Verizon Executive Vice President Randal Milch.(link1) Still, there remains plenty of skepticism that has raised many questions about restructuring the web to make it content-centric.(link4) By doing so, every resource (i.e. movie stream, webpage, etc...) would have a unique address and thus the possibility to be shared peer to peer rather than from a few known, easily identifiable servers. One of the most notable advantages of adopting a content-centric network is potentially making it more difficult for interfering parties to censor or manipulate the internet. In the past, attacks aimed at spoofing the BitTorrent protocol have been effectively combated by means of encryption; thus, if ever it was the case that an ISP wanted to manipulate traffic on their network, encryption of the content-centric protocol would suffice as a counter.(link4) Van Jacobsen, a PARC Xerox Research fellow, and other huge proponents suggest that named data is a far better abstraction than named hosts as related to the structure of the World Wide Web. According to these proponents, building a content-centric web not only empowers proponents of network neutrality like BitTorrent-- but also addresses far bigger challenges imposing the future development of the Internet. </p>
<br>
<h2> Scaling Problems with Client-Server Oriented Web</h2>
<p>Teresa Lunt, vice president of PARC’s Computing Science Laboratory, gives a very simple explanation for CCN communication: &rsquo;You replace the concept of the IP address as the defining entity in the network with the name of the content. Now all the talk in the network is about ‘Have you seen this content?’ and ‘Who needs this content?’ as opposed to ‘What is the routing path to particular terminus in the network?’ It’s a simple idea, but it makes a lot of things possible.” (link4) One thing it makes possible is an effective, practical  the solution to traffic congestion associated with our currently centralized Web. Jacobsen argues that the Internet infrastructure was never designed to carry such a high volume of multimedia data traffic, which is the majority of the traffic on the Web now. He projects that wireless and land-line bandwidth speeds will not be able to keep up with the growing volume of multimedia traffic.(link4)/page1 However, with memory being a much cheaper resource than in the early stages of the Internet, it is a much more appealing option to cahche popular content near the edges of the network. In this way, we can divert traffic from the Internet's core and reduce the total distance that content would otherwise travel from the center to edge every time it's requested at the edge.(link4) What's important is that this sort of caching techinque would flourish in a CCN environment. Lunt explains that in a content-centric network, if you want to watch a video, you don’t have to go all the way back to the source: “I only have to go as far as the nearest router that has cached the content, which might be somebody in the neighborhood or somebody near me on an airplane or maybe my husband’s iPad.” The CCN would have a protocol that would specifically locate the resource, and possibly the nearest source, as opposed to finding the original source. This brings into discussion two very important things: (1) What must this new protocol and system look like? (2) What does this CCN-based caching stragety mean for the resource intensive, corporate content distribution networks in place and underway?</p>
<br>
<h2>A Solution to CDN Threat to Net Neutrality </h2>
<p>In a paper published by the Penn State University Press authored by Manuel Palacin and colleagues, the authors place emphasis on the threat of Content Distribution Networks to the competitive nature of the Internet Ecosystem.(link1) The authors of the study explicitly encourage policymakers to address how CDNs affect network neutrality. They argue that the potential effects on the Internet ecosystem are potentially the same as those of traffic prioritization: both strategies result in a relatively better quality user-experience at a monetary price--smaller entities that cannot afford the upgrade end up losing quality and consequently, clients.The authors strongly demand that the debate over network neutrality should also include CDNs. Their efforts to soften the threat of CDNs to smaller online-content producers may potentially be aided aided by forthcoming CCN caching methods. Caching at different points in the network is exactly what content distribution networks (CDNs) like Akamai do for their high-end corporate clients, so that Internet videos will start playing faster, for example. But in a content-centric world, Lunt says, the whole Internet would be a CDN. “Caching becomes part of the model as opposed to something you have to glue onto the side.”(link2) Efficient and stragetic CCN caching has the potential to interfere with the future growth of CDNs and challenge businesses in the &rsquo;content industry&rsquo;. Companies such as Facebook, Microsoft, and Google have spent hundreds of billions of dollars erecting walled proprietary storage and distribution infrastructures, designed wholly around the client-server model and often reachable only via &rsquo;tollbooths&rsquo; like the iTunes Store or Xbox Live.(link2) The deployment of a CCN architecture may force such businesses in the content delivery industry to reevaluate their overall strategy. That being said, recent trends show that the actual bit delivery business constitutes a diminishing fraction of the revenues of CDNs. Third-Party CDNs are increasingly supporting additional services such as application delivery, dynamic site acceleration, real-time analytics, security, consulting as well as tailor-made solutions to enterprises for content and advertisement management(link5). For instance, supplementary services now form more than half of Akamai’s annual revenues (link5). This evidence confirms the possibility of a scenario where CDNs package bit delivery with supplementary services in order to remain competitive. </p>
<br>
<h2>Economic Incentives for Deployment of Content Centric Network Architectures</h2>
<p>In a recent study by researchers from Jacobs University Bremen and Carnegie Mellon University, the authors analyze the economic aspects of CCN deployment. They argue that of all the forseeable content centric network architectures, there are only two that are economically viable. One of these such proposed architectures revolves around edge networks providing the CCN storage infrastructure through a transaction broker. The other strategy requires paying third-parties a certain amount to deploy storage infrastructure in the network; the amount corresponds specifically to the realized benefits from a storage node. The argument here is that without some form of payment flow, networks will fail to deploy sufficient caching infrastructure to successfully sustain a global CCN. CCN architectures must incorporate features that make it easy to implement payment mechanisms to support caching-based business models. Furthemore, the authors explain that in order to be useful, these features should exhibit low transaction costs and provide a means for transparent verification. As an example, they suggest CCN protocols should make it easy for publishers to indicate their willingness to partake in the caching market and the explicit conditions under which they will participate. In addition, there must be a reevaluation of the hierarchy of trust inherent to the CCN. Namely, these new protocols must enable networks to easily determine whether to cache an object based on easily identifiable and trustworthy information about the publisher of the object or its authorized intermediaries. The expectation here is that these features will hopefully provide networks with the capability to aggregate useful information about content delivered on behalf of publishers across multiple networks. </p>
<br>
<h2>Future Models of the Underlying CCN Protocol</h2>
<p>As for the protocol that will constitute the CCN, it might not radically different from what we are already used to. According to the researchers from Carnegie Mellon mentioned above, current research on future Internet architectures is best categorized into &rsquo;evolutionary approaches&rsquo; and &rsquo;clean slate approaches&rsquo;.(link5) As they explain, evolutionary approaches design protocols and technologies to improve the Internet, taking the current architecture as a constraint. Evolutionary solutions still assume host-centric networking and use IP addresses for identification among other things. Evolutionary research targets the design better caching techniques, overlay networks and protocols to help to maximize the efficiency of content distribution. The article mentions eevolutionary ideas have also been proposed and, in some cases, deployed to address other challenges such as security. These include Internet Protocol Security (IPSec), Transport Layer Security (TLS), Secure Border Gateway Protocol (S-BGP) and Domain Name System Security Extensions (DNSSEC).(link5) Clean slate approaches, on the other hand, design solutions to address the root cause of identified problems and are not constrained by the current Internet architecture.(link5) Clean slate designs usually advocate a break from three main design paradigms of the Internet. These approaches propose a departure from the host-centric networking (HCN) design of the current Internet. Surprisingly, clean slate approaches advocate stronger notions of identity. For instance, the concept of intrinsic security, where security properties are decoupled from path and location attributes has gained a lot of attention. Such intrinsic security properties can be achieved by using cryptographic primitives to name content, hosts and services. For instance, intrinsic security can be achieved by using a hash of the content or the hash of a public key representing the host or service as the name. This shift is intended to make the Internet fundamentally secure (link5). </p>
<br>
<h2>P2P CCN Architectures and Net Neutrality</h2>
<p>Some recent news points to the possibility that the BitTorrent protocol can be thrown under the hood of a browser to make this content-centric web easily navigable. BitTorrent is a peer to peer file sharing protocol that solves the problem of transferring large files quickly in the face of remarkably slow upload rates. In an interview with Fast Company, the inventor and founder of the Bittorrent company compares sending a concert recording between peers as being similar to sending a &rsquo;pickle through a straw&rsquo;. (link3) His vision: What if many computers all had the same concert recording? Then maybe all these computers could simultaneously send little bits of the concert to a new downloader's computer, where the bits could be properly assembled. (i.e. Now there are many straws, each sending little slices of the pickle). The result is that a file which originally took days to download is now transferable in a matter of hours. The grandeur of this protocol has lead it to rise to incredible popularity on the internet. According to a retired internet-traffic management firm CacheLogic, the BitTorrent protocol accounted for 30% of al Internet traffic by 2004. More recently, it accounts for far less because of a new effort by BitTorrent Inc. to manage the protocol's bandwidth use as a result of streaming sites competing for bandwidth. Today, BitTorrent is launching a new technology name &rsquo;Project Maelstrom&rsquo;, a web browser that &rsquo;can power a new way for web content to be published, accessed and consumed&rsquo;. In their public announcement of the new launch, BitTorrent says the result of Project Maelstrom will be &rsquo;Truly an Internet powered by people, one that lowers barriers and denies gatekeepers their grip on our future.&rsquo; Evidently, their greater goal is to aid in the fight towards net neutrality by creating an alternative to the currently centralized client-server model rather than shaping policy.(link3) Going back to our prediction for the new protocol, there is evidence that the new protocol beneath the CCN does not necessarily have to dispose of the HTTP protocol altogther. For one, the BitTorrent protocol utilizes HTTP. The BitTorrent protocol defines a &rsquo;tracker&rsquo; to initiate node communication as related to a specific resource. In one of the BitTorrent specifications, the tracker is defined as an HTTP/HTTPS service which responds to HTTP GET requests. These requests include metrics from clients that help the tracker keep overall statistics about the torrent. The response also includes a peer list that helps the client participate in the torrent. The base URL consists of the "announce URL" as defined in the metainfo (.torrent) file. The parameters are then added to this URL, using standard CGI methods (i.e. a '?' after the announce URL, followed by 'param=value' sequences separated by '&').(link6).</p>
<br>
<h3> Sources </h3>
<a href="http://www.wsj.com/articles/SB10001424052702304049704579320500441593462">Court Tosses Rules of Road for Internet (link1)</a>
<br>
<a href="http://www.xconomy.com/san-francisco/2012/08/07/the-next-internet-inside-parcs-vision-of-content-centric-networking/">The Next Internet? Inside PARC’s Vision of Content Centric Networking (link2) </a>
<br>
<a href="http://www.fastcompany.com/3027441/the-infinite-lives-of-bittorrent">The Infinite Lives of BitTorrent(link3)</a>
<br>
<a href="http://blog.bittorrent.com/2014/04/24/net-neutrality-we-need-a-better-deal/">Net Neutrality- We need a Better Deal (link4)</a>
<br>
<a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1258&context=dissertations">Economic Incentives in Content-Centric Networking: Implications for Protocol Design and Public Policy (link5)</a>
<br>
<a href="https://wiki.theory.org/BitTorrentSpecification#Tracker_HTTP.2FHTTPS_Protocol"> BitTorrent Specification Tracker (link6)</a> 

</html>

